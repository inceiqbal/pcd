{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c6640fd-df65-4f7d-8451-288ae01d358a",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "This project aims to detect signs of tuberculosis (TB) in chest X-ray images using classical digital image processing techniques. We implement a full image processing pipeline—from preprocessing to feature extraction and analysis—to highlight the effectiveness of each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02990582-952a-4ab2-bc2c-fc3d74c86bf4",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cec8cc-979a-49c3-9f92-90517f283ffe",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec0cf19d-ed2d-47ab-a7aa-629b3ad57fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import remove_small_objects, closing, disk\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a29a7-e95a-4300-9dcd-5d8f2e8d3cae",
   "metadata": {},
   "source": [
    "#### Load .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bcea758-04c6-4901-bc10-80ac8264c827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f295efb-7ea7-4827-8fc8-05c3e2fd22af",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d8a05d-12d8-452d-8e7a-76c28f5cf0b7",
   "metadata": {},
   "source": [
    "#### CLAHE (Contrast Limited Adaptive Histogram Equalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7d29f88-746a-4166-bc73-f0179138b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_clahe(img):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    return clahe.apply(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969002c-12e0-4790-a76d-fc9b9caa8fa3",
   "metadata": {},
   "source": [
    "#### Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5be3a6a1-5196-4c1d-b760-f47dacebfc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = apply_clahe(img)\n",
    "    img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b904ea-ea65-41ac-87fb-c9a1f7b391a0",
   "metadata": {},
   "source": [
    "## Image Processing & Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2772f6a5-fa2d-49ba-91a5-993ee89d1cd2",
   "metadata": {},
   "source": [
    "### Otsu Thresholding + Morphological Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e0393b-d5e3-42e5-bfa4-0bbb39665f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_mask(img):\n",
    "    try:\n",
    "        t = threshold_otsu(img)\n",
    "        mask = img > t\n",
    "        mask = remove_small_objects(mask, min_size=500)\n",
    "        mask = closing(mask, disk(5))\n",
    "        return mask\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1f4b31-e377-41fa-8f7c-8d1c0404a409",
   "metadata": {},
   "source": [
    "### Labeling & Region Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae314dab-8f7c-4363-88f5-e24f02a8a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(mask, img):\n",
    "    labeled = label(mask)\n",
    "    regions = regionprops(labeled, intensity_image=img)\n",
    "    if not regions:\n",
    "        return None\n",
    "    r = max(regions, key=lambda x: x.area)\n",
    "    minr, minc, maxr, maxc = r.bbox\n",
    "    cropped = img[minr:maxr, minc:maxc]\n",
    "    cropped = cv2.resize(cropped, (64, 64))\n",
    "    cropped = np.uint8(cropped / np.max(cropped) * 255)\n",
    "\n",
    "    glcm = graycomatrix(cropped, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    return {\n",
    "        'area': r.area,\n",
    "        'perimeter': r.perimeter,\n",
    "        'eccentricity': r.eccentricity,\n",
    "        'mean_intensity': r.mean_intensity,\n",
    "        'solidity': r.solidity,\n",
    "        'glcm_contrast': graycoprops(glcm, 'contrast')[0, 0],\n",
    "        'glcm_homogeneity': graycoprops(glcm, 'homogeneity')[0, 0],\n",
    "        'glcm_energy': graycoprops(glcm, 'energy')[0, 0],\n",
    "        'glcm_correlation': graycoprops(glcm, 'correlation')[0, 0],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7545b2b1-bfc2-48b9-8e9d-1e883866267a",
   "metadata": {},
   "source": [
    "## Analysis & Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de756e9-f210-4a33-b9fe-2da550a92f38",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m classes = [\u001b[33m'\u001b[39m\u001b[33mTuberculosis\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mNormal\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      3\u001b[39m features = []\n\u001b[32m      5\u001b[39m visual_samples = {\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28mcls\u001b[39m: random.choice(\u001b[38;5;28mlist\u001b[39m((\u001b[43mdata_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m).iterdir()))\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m classes\n\u001b[32m      8\u001b[39m }\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m classes:\n\u001b[32m     11\u001b[39m     class_dir = data_dir / \u001b[38;5;28mcls\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "data_dir = os.getenv('DATA_DIR')\n",
    "classes = ['Tuberculosis', 'Normal']\n",
    "features = []\n",
    "\n",
    "visual_samples = {\n",
    "    cls: random.choice(list((data_dir / cls).iterdir()))\n",
    "    for cls in classes\n",
    "}\n",
    "\n",
    "for cls in classes:\n",
    "    class_dir = data_dir / cls\n",
    "    for fname in tqdm(class_dir.iterdir()):        \n",
    "        img = preprocess_image(fname)\n",
    "\n",
    "        if fname == visual_samples[cls]:\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(cv2.imread(fname, cv2.IMREAD_GRAYSCALE), cmap='gray')\n",
    "            plt.title(f'{cls} - Original')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 3, 2)\n",
    "            clahe_img = apply_clahe(cv2.resize(cv2.imread(fname, cv2.IMREAD_GRAYSCALE), (256, 256)))\n",
    "            plt.imshow(clahe_img, cmap='gray')\n",
    "            plt.title('CLAHE')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            plt.title('Gaussian Blur')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.suptitle(f'{cls} - Preprocessing Visualization', fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        if cls == 'Normal':\n",
    "            feats = {\n",
    "                'area': 0, 'perimeter': 0, 'eccentricity': 0,\n",
    "                'mean_intensity': np.mean(img), 'solidity': 0,\n",
    "                'glcm_contrast': 0, 'glcm_homogeneity': 0,\n",
    "                'glcm_energy': 0, 'glcm_correlation': 0\n",
    "            }\n",
    "        else:\n",
    "            mask = segment_mask(img)\n",
    "            if mask is None:\n",
    "                continue\n",
    "            feats = extract_features(mask, img)\n",
    "            if feats is None:\n",
    "                continue\n",
    "\n",
    "        feats['label'] = cls\n",
    "        features.append(feats)\n",
    "\n",
    "df = pd.DataFrame(features)\n",
    "df.to_csv('tb_features_glcm.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4cdbcd-f969-4605-aaff-e2e6571a5322",
   "metadata": {},
   "source": [
    "## Comparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57619bc-b958-42f9-ae9f-29525198afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Boxplot for key features\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df, x='label', y='glcm_contrast')\n",
    "plt.title(\"GLCM Contrast: TB vs Normal\")\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "corr = df.drop(columns='label').corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83608984-8ff9-41b7-b30a-cbf6eb8257a4",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f228e671-44fd-4853-a836-58a6736602f3",
   "metadata": {},
   "source": [
    "- CLAHE + Gaussian Blur preprocessing improved visibility of lung lesions.\n",
    "- Otsu + morphological ops successfully isolated lung/lesion regions.\n",
    "- GLCM features (e.g., contrast, correlation) were more discriminative than basic shape features.\n",
    "- The dataset allows clear visual and quantitative differentiation between TB and Normal classes.\n",
    "\n",
    "Future work: apply ML classifier (SVM/KNN) on features, or try full lung segmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590bae0f-94eb-458e-89fd-9275669fffe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
